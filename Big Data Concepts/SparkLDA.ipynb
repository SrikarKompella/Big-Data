{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.sql import SQLContext\n",
    "import re\n",
    "\n",
    "n_stopwords = 50      # Number of most common words to remove, trying to eliminate stop words\n",
    "n_topics = 3\t            # Number of topics we are looking for\n",
    "n_wordspertopic = 10    # Number of words to display for each topic\n",
    "maxiter = 35         # Max number of times to iterate before finishing\n",
    "\n",
    "sc = SparkContext('local', 'PySPARK LDA Example')\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.wholeTextFiles('cookbook_text/*').map(lambda x: x[1])\n",
    "tokens = data \\\n",
    "    .map( lambda document: document.strip().lower()) \\\n",
    "    .map( lambda document: re.split(\"[\\s;,#]\", document)) \\\n",
    "    .map( lambda word: [x for x in word if x.isalpha()]) \\\n",
    "    .map( lambda word: [x for x in word if len(x) > 3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "termCounts = tokens \\\n",
    "    .flatMap(lambda document: document) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey( lambda x,y: x + y) \\\n",
    "    .map(lambda tuple: (tuple[1], tuple[0])) \\\n",
    "    .sortByKey(False)\n",
    "\n",
    "threshold_value = termCounts.take(n_stopwords)[n_stopwords - 1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = termCounts \\\n",
    "    .filter(lambda x : x[0] < threshold_value) \\\n",
    "    .map(lambda x: x[1]) \\\n",
    "    .zipWithIndex() \\\n",
    "    .collectAsMap()\n",
    "\n",
    "def document_vector(document):\n",
    "    id = document[1]\n",
    "    counts = defaultdict(int)\n",
    "    for token in document[0]:\n",
    "        if token in vocabulary:\n",
    "            token_id = vocabulary[token]\n",
    "            counts[token_id] += 1\n",
    "    counts = sorted(counts.items())\n",
    "    keys = [x[0] for x in counts]\n",
    "    values = [x[1] for x in counts]\n",
    "    return (id, Vectors.sparse(len(vocabulary), keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = tokens.zipWithIndex().map(document_vector).map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_voc = {value: key for (key, value) in vocabulary.items()}\n",
    "\n",
    "with open(\"output.txt\", 'w') as f:\n",
    "    lda_model = LDA.train(documents, k=n_topics, maxIterations=maxiter)\n",
    "\n",
    "    topic_indices = lda_model.describeTopics(maxTermsPerTopic=n_wordspertopic)\n",
    "        \n",
    "    # Print topics, showing the top-weighted 10 terms for each topic\n",
    "    for i in range(len(topic_indices)):\n",
    "        f.write(\"Topic #{0}\\n\".format(i + 1))\n",
    "        for j in range(len(topic_indices[i][0])):\n",
    "            f.write(\"{0}\\t{1}\\n\".format(inv_voc[topic_indices[i][0][j]] \\\n",
    "                .encode('utf-8'), topic_indices[i][1][j]))\n",
    "            \n",
    "\n",
    "    f.write(\"{0} topics distributed over {1} documents and {2} unique words\\n\" \\\n",
    "        .format(n_topics, documents.count(), len(vocabulary)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
